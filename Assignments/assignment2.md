# Assignment 2: Usability Testing

## What is usability testing?
Usability testing is a way to gather empirical data from your users about how usable your product is. 
This testing can be done early on during the product development as a formative assessment or later after the product launches as validation.
Testing early on can eliminate usability issues before the product is launched, saving time, money, and effort in the long run.
Testing later on to validate the product can help ensure that it is up to standards. 
Regardless of when it is done, usability testing gives insight on how real users interact with your product and what usability issues they encounter.

To conduct usability testing, you need:

* a location (lab, cafe, etc - anywhere you and the user can sit and use the product)
* people (a moderator is optional, a user is required!)
* a product to test
* a questionnaire

The questionnaire typically consists of realistic tasks that users might do while using your product. These tasks should be outlined very concretely by the moderator, so that they can clearly assess whether the user was able to complete it or not.
Questions aim to measure the efficiency, effectiveness, and satisfaction of your product. These are the three core principles of usability. 
Besides giving users realistic scenarios in which to use the product, you can include Likert scale measures that capture more subjective aspects of the user experience, such as likelihood that the user would continue to use the product.

## How heuristic evaluation can inform usability testing
In assignment 1, I conducted a heuristic evaluation on the Frick Collection Virtual Tour website. I identified three major issues with the virtual tour experience:

1. Users are unable to see what pieces or collections are held in each room of the museum from the virtual tour screen
2. The map is not readily accessible from the virtual tour screen
3. Users are unable to view an art piece in high resolution or full screen

With these issues in mind, I crafted three scenarios to test with usability testing:

1. Finding a specific painting by name
2. "Walking" through the virtual museum by traveling from room to room
3. Viewing multiple paintings from one room, in detail

For the detailed step-by-step scenarios I included, check out the full [questionnaire](https://forms.gle/RsvqniBv2tfaro7S6).

## Pilot Usability Testing for The Frick Collection Virtual Museum Tour
Before I do a full usability test with this website, I conducted this pilot test to evaluate whether I have chosen suitable tasks and questions that address the usability issues of interest.

For the pilot test, I used ActivePresenter to record the user and their interaction with the website. Because of limited access to formal testing spaces, I set up a minimalist portable test lab in my apartment consisting of my laptop, mouse, and desk.

View the pilot test [here](https://drive.google.com/open?id=1mLQ8xWZVQ2Cs4S_AJsWJUXzzl03UD0pc).


### Pilot Testing Process
To get the most out of our usability testing, I needed to consider what questions to ask regarding the user's experience the website before, during, and after completing the usability test tasks. 

The questionnaire can be broken into the following segments:

1. Informed consent
2. Background questions
3. Pre-test questions
4. Task Scenarios
5. Post-test questions
    * [System Usability Scale (SUS)](https://www.usability.gov/how-to-and-tools/methods/system-usability-scale.html)
    * [Product Satisfaction Card](https://elearn.uni-sofia.bg/pluginfile.php/55103/mod_resource/content/0/Resources/Systems_Evaluation/DesirabilityToolkit.doc)
6. Demographic questions

#### Informed Consent
This is crucial to any research study, as it informs the user about the purpose of the testing and about their rights as a participant. 

#### Background questions
These are meant to capture any prior experiences that might influence the participant's test performance, such as previous exposure to the website or similar sites.

In this case, I asked the user whether they had visited the Frick Collection Virtual Tour site before.

#### Pre-test questions
These can help clarify the goals of the usability test, including initial impressions and whether they value the product.

Here I asked the user how easy/difficult the virtual tour interface appeared and what they thought the controls at the bottom did.

#### Task Scenarios
This is the core of the usability test. In this section, I focused on testing the effectiveness of the site (whether the user could complete certain tasks or not). Through the user's facial expressions and verbal comments, I also gleaned a bit about their satisfaction.

Based on the findings of my heuristic evaluation, I decided on these three tasks:

1. Finding a specific painting by name
* In this task, I wanted to test whether the user would find it difficult to jump between the search function on the main site and the virtual tour itself
* Since the paintings are catalogued in a database separate from the virtual tour window, I anticipated some difficulty here
2. "Walking" through the virtual museum by traveling from room to room
* I chose this task because I imagine that users who seek out a virtual museum experience expect some degree of immersion or similarity to a real life museum visit
* I foresaw some difficulties here due to the poor integration of the museum map and the virtual rooms
3. Viewing multiple paintings from one room, in detail
* Another test of immersion
* I wanted to test how the user reacted to the limited ability to view the paintings in an immersive way, which is a central component of the museum experience

#### Post-test questions
Here I assessed user perceptions of the difficulty and efficiency of tasks they just completed. Additionally, I included standard measures of satisfaction (SUS) and perceptions (Product Satisfaction Card).

This section mainly consisted of statements paired with Likert Scale responses, which the users could endorse to different degrees.

#### Demographic questions
These were standard questions to gather demographic information about the user. I placed these at the end of the questionnaire to prevent these questions from influencing responses on the usability test (stereotype threat, bias).

## What I learned
* Users' evaluation of the severity of problems differed quite a bit from my own.
* Users don't always take the path that you would have taken to solve the problem.
* Users are willing to tolerate some more global usability issues (needing to open separate tabs to view artwork in detail), but may not tolerate more acute, smaller usability issues (not being able to scroll while hovering over specific content).
* Some questions ("How likely are you to do this task?") were ambiguous and needed my verbal clarification. These could be better articulated on the questionnaire.
* Because of the unique purpose of this website (entertainment/art consumption), I should have included more measures of subjective sastisfaction that are specific to museum visits. For example, I could have included more qualitative measures of how well the site highlighted the art or how likely they would prefer this format over real-life museum visits. 
* Next time, I would also include measures of how much they would value a website that allows them to do virtual museum tours. This could inform me about how useful the website is.
